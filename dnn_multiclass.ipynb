{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "541af361-f362-487c-b15c-f607a982246f",
   "metadata": {},
   "source": [
    "# Multiclass classification with deep neural networks\n",
    "This is deep neural network implementation from scratch, without using any machine learning libraries.\n",
    "\n",
    "The dataset used is MNIST dataset of handwritten images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7526df53-9604-48df-b38f-7e3003bc4fb6",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [1 - Load data](#1)\n",
    "- [2 - Initialize Parameters](#2)\n",
    "- [3 - Cost Function](#3)\n",
    "- [4 - Activation Function](#4)\n",
    "- [5 - Forward Propagation](#5)\n",
    "- [6 - Backward Propagation](#6)\n",
    "- [7 - Update Parameters](#7)\n",
    "- [8 - Train Model](#8)\n",
    "- [9 - Predict](#9)\n",
    "- [10 - Print Images](#10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d146ab8-0a15-40bb-a251-00fc072193f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import * \n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43391347-9a10-4600-8408-546a02db5478",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "### Load data\n",
    "Dataset contains training and test sets.\n",
    "Each example is flattened `28x28` greyscale image of with shape `784 (28 * 28)`.\n",
    "\n",
    "By default label set is a vector that contains single digit from `0` to `9`. \n",
    "In order to make it work first we need to expand this into a 10 dimensional matrix\n",
    "e.g if the label is `4` we expand it to be `[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]`\n",
    "After this the label set shape will become `10 x 60000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2726339-25e7-46fa-bf5f-b3d28ccaf8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  60000\n",
      "Number of testing examples:   10000\n",
      "------\n",
      "Flattened image size:         784\n",
      "------\n",
      "x_train shape:                (784, 60000)\n",
      "y_train shape initial:        (1, 60000)\n",
      "------\n",
      "y_train shape expanded:       (10, 60000)\n",
      "------\n",
      "x_test shape:                 (784, 10000)\n",
      "y_test shape:                 (1, 10000)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train_raw, x_test, y_test = load_mnist() # Load mnist dataset\n",
    "\n",
    "m_train = x_train.shape[1] # Number of examples\n",
    "num_px = x_train.shape[0] # Number of input elements\n",
    "m_test = x_test.shape[1] # Number of test examples\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "\n",
    "# Expand Y values to vectors\n",
    "# e.g. 4 will become [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "y_train = np.zeros((10, y_train_raw.shape[1]))\n",
    "m = list(range(y_train_raw.shape[1]))\n",
    "n = list(y_train_raw.squeeze())\n",
    "y_train[n[:], m[:]] = 1\n",
    "\n",
    "print ('Number of training examples: ', m_train)\n",
    "print ('Number of testing examples:  ', m_test)\n",
    "print ('------')\n",
    "print ('Flattened image size:        ', num_px)\n",
    "print ('------')\n",
    "print ('x_train shape:               ', x_train.shape)\n",
    "print ('y_train shape initial:       ', y_train_raw.shape)\n",
    "print ('------')\n",
    "print ('y_train shape expanded:      ', y_train.shape)\n",
    "print ('------')\n",
    "print ('x_test shape:                ', x_test.shape)\n",
    "print ('y_test shape:                ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c5c767-2bda-443a-be81-1cd21a8be1ec",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b74188-3068-4d43-9edc-bd2b1264cdc5",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "### Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46bc8204-6f50-4bf4-98e8-3884b92f7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(dims):\n",
    "    \"\"\"\n",
    "    Initializes parameters\n",
    "        Wl -- to random values\n",
    "        bl -- to zeros\n",
    "        \n",
    "    Arguments:\n",
    "        dims -- list of layer sizes\n",
    "    \n",
    "    Returns:\n",
    "        parameters\n",
    "            Wl -- weights matrix, shape (current layer nodes, previous layer nodes)\n",
    "            bl -- biases vector, shape (current layer nodes, 1)\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    L = len(dims) # Number of layers\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(dims[l], dims[l-1]) / np.sqrt(dims[l-1])\n",
    "        parameters['b' + str(l)] = np.zeros((dims[l], 1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (dims[l], dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d857a2-15cf-455a-959f-cc89e734170b",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## Cost Function\n",
    "\n",
    "Compute the cross-entropy cost $J$, using the following formula: $$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right))Â \\tag{1}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f621bdd-5b33-4f59-9d3f-2a0ca9f3f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "\n",
    "    Arguments:\n",
    "        AL -- output vector(predictions), shape (number of classes, number of examples)\n",
    "        Y -- actual values matrix, shape (number of classes, number of examples)\n",
    "\n",
    "    Returns:\n",
    "        cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    \n",
    "#     cost = (1./m) * np.sum(-np.dot(Y, np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T), keepdims=True)\n",
    "\n",
    "    cost = -(1./m) * np.sum((Y, np.log(AL)) + (1-Y, np.log(1-AL)), keepdims=True)\n",
    "    \n",
    "    print(cost.shape)\n",
    "    cost = np.squeeze(cost)    \n",
    "    \n",
    "#     assert cost.shape == (), 'cost value should be a scalar'\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b52f2-446e-4672-9e19-5bd6e77f006e",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "### Activation Function\n",
    "\n",
    "In this notebook, you will use two activation functions:\n",
    "\n",
    "- **Sigmoid**: $\\sigma(Z) = \\sigma(W A + b) = \\frac{1}{ 1 + e^{-(W A + b)}}$.\n",
    "\n",
    "\n",
    "\n",
    "- **ReLU**: $A = RELU(Z) = max(0, Z)$. \n",
    "\n",
    "\n",
    "- **`sigmoid_backward`**: Implements the backward propagation for SIGMOID unit.\n",
    "\n",
    "- **`relu_backward`**: Implements the backward propagation for RELU unit.\n",
    "\n",
    "If $g(.)$ is the activation function, \n",
    "`sigmoid_backward` and `relu_backward` compute $$dZ^{[l]} = dA^{[l]} * g'(Z^{[l]}). \\tag{2}$$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4294f1e2-f9b1-4417-b68a-3b018e7ecee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Calculates sigmoid of any input\n",
    "    \n",
    "    Arguments:\n",
    "        Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "        A -- sigmoid of input Z, shape (same as Z)\n",
    "        cache -- returns Z for caching, useful in backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Calculates RELU.\n",
    "\n",
    "    Arguments:\n",
    "        Z -- numpy array of any shape\n",
    "\n",
    "    Returns:\n",
    "        A -- Activation of Z\n",
    "        cache -- returns Z for caching, useful in backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert A.shape == Z.shape, 'A should be same shape as Z'\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Calculates the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "        dA -- post-activation gradient, of any shape\n",
    "        cache -- returns Z for caching, useful in backpropagation\n",
    "\n",
    "    Returns:\n",
    "        dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # convert dz to a numpy array.\n",
    "    \n",
    "    # When z <= 0, set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert dZ.shape == Z.shape, 'dZ should be the same shape as Z'\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Calculates the backward propagation for a single SIGMOID unit.\n",
    "\n",
    "    Arguments:\n",
    "        dA -- post-activation gradient, of any shape\n",
    "        cache -- returns Z for caching, useful in backpropagation\n",
    "\n",
    "    Returns:\n",
    "        dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert dZ.shape == Z.shape, 'dZ should be the same shape as Z'\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b60ac5-49cc-414a-b848-3d3027f10770",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## Forward Propagation\n",
    "Calculate forward propagation:\n",
    "\n",
    "$$Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}\\tag{3}$$\n",
    "Followed by an activation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb15cb9-26dd-47a4-a3e1-28af07a88a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Calculates activations of Z and passes to the next layer.\n",
    "    \n",
    "    Arguments:\n",
    "        A_prev -- activations of previous layer\n",
    "        W -- weight matrix of the current layer\n",
    "        b -- bias values of the current layer\n",
    "        activation -- type of activation function\n",
    "    \"\"\"\n",
    "    activation = activation.lower()\n",
    "    assert activation == 'relu' or activation == 'sigmoid', \"activation should be either 'relu', or 'sigmoid'\"\n",
    "    \n",
    "    Z = W.dot(A_prev) + b\n",
    "    assert Z.shape == (W.shape[0], A_prev.shape[1]), 'wrong Z shape'\n",
    "\n",
    "    linear_cache = (A_prev, W, b)   \n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        A, activation_cache = sigmoid(Z)    \n",
    "    elif activation == \"relu\":\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert A.shape == (W.shape[0], A_prev.shape[1]), 'wrong A shape'\n",
    "    \n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88e3dbee-2709-4f24-a4be-4ed7c77b122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, parameters):\n",
    "    \"\"\"\n",
    "    Propagates forward.\n",
    "    \n",
    "    Arguments:\n",
    "        X -- numpy array of input data, shape (number of examples, input size)\n",
    "        parameters -- initialized parameters\n",
    "    \n",
    "    Returns:\n",
    "        AL -- output layer of predictions\n",
    "        caches -- list of caches containing:\n",
    "                    cache of relu activations\n",
    "                    cache of sigmoid activation of output layer\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2 # number of layers\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = forward_pass(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "        caches.append(cache)        \n",
    "    \n",
    "    AL, cache = forward_pass(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "\n",
    "    assert AL.shape == (dims[len(dims) - 1],X.shape[1]), 'wrong output layer shape'\n",
    "\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dc3620-4af5-4fbb-895e-db28de3c9bcb",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "### Backward Propagation\n",
    "\n",
    "For layer $l$, the linear part is: $Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$ (followed by an activation).\n",
    "\n",
    "Suppose you have already calculated the derivative $dZ^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial Z^{[l]}}$. You want to get $(dW^{[l]}, db^{[l]}, dA^{[l-1]})$.\n",
    "\n",
    "\n",
    "The three outputs $(dW^{[l]}, db^{[l]}, dA^{[l-1]})$ are computed using the input $dZ^{[l]}$.\n",
    "\n",
    "$$ dW^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T} \\tag{4}$$\n",
    "$$ db^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)}\\tag{5}$$\n",
    "$$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]} \\tag{6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f318aa-1360-4e12-9ceb-1b707e2c5ee9",
   "metadata": {},
   "source": [
    "Pass parameters back by one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f45009-52b6-48ee-b88b-c4fc5dd305f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Calculates derivative of activations and passes to the previous layer.\n",
    "    \n",
    "    Arguments:\n",
    "        dA -- post-activation gradient of the current layer\n",
    "        cache -- tuple of caches (linear_cache, activation_cache), saved during forward propagation\n",
    "        activation -- name of activation function\n",
    "    \n",
    "    Returns:\n",
    "        dA_prev -- Gradient of the cost with respect to the activation of the previous layer, same shape as A_prev\n",
    "        dW -- Gradient of the cost with respect to W, same shape as W\n",
    "        db -- Gradient of the cost with respect to b, same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "        \n",
    "    A_prev, W, b = linear_cache\n",
    "    m = A_prev.shape[1]    \n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ffb706-b532-4849-86a0-c1b6923760bf",
   "metadata": {},
   "source": [
    "Backward propagate through all the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3238b4aa-b699-4cfd-82bc-74210a994910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagate(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Propagates backwards\n",
    "    \n",
    "    Arguments:\n",
    "        AL -- output layer predictions\n",
    "        Y -- actual values\n",
    "        caches -- list of caches containing:\n",
    "                    cache of relu activations\n",
    "                    cache of sigmoid activations of the last layer\n",
    "    \n",
    "    Returns:\n",
    "        grads -- A dictionary of gradients 'dA', 'dW', 'db'\n",
    "\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    # Initialize the backpropagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = backward_pass(dAL, current_cache, activation = \"sigmoid\")\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = backward_pass(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80844b5-76e7-4230-bc42-487075a08931",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "### Update Parameters\n",
    "\n",
    "Update the parameters of the model, using gradient descent: \n",
    "\n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} \\tag{8}$$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} \\tag{9}$$\n",
    "\n",
    "where $\\alpha$ is the learning rate. \n",
    "\n",
    "After computing the updated parameters, store them in the parameters dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bad31731-6938-42ba-afd5-527e96746b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters.\n",
    "    \n",
    "    Arguments:\n",
    "        parameters -- dictionary of parameters \n",
    "        grads -- dictionary of gradients\n",
    "    \n",
    "    Returns:\n",
    "        parameters -- dictionary of updated parameters 'W' and 'b'\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77d179-1bdd-40f7-bb86-6ac02933247f",
   "metadata": {},
   "source": [
    "<a name='8'></a>\n",
    "### Train Model\n",
    "\n",
    "User above defined functions to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c17eb1-949f-4ad3-879c-c35f96115a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, dims, learning_rate = 0.01, epochs = 100, print_cost=False):\n",
    "    \"\"\"\n",
    "    Trains full deep neural network.\n",
    "    \n",
    "    Arguments:\n",
    "        X -- numpy array of input data, shape (flattened image pixel number, number of examples)\n",
    "        Y -- actual values\n",
    "        layers_dims -- list of layers\n",
    "        learning_rate -- learning rate\n",
    "        epochs -- number of iterations\n",
    "        print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "        parameters -- learned parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    costs = []\n",
    "\n",
    "    parameters = initialize_parameters(dims)\n",
    "        \n",
    "    # Gradient descent\n",
    "    for i in range(0, epochs):\n",
    "\n",
    "        AL, caches = forward_propagate(X, parameters)\n",
    "        \n",
    "        cost = compute_cost(AL, Y)\n",
    "\n",
    "        grads = backward_propagate(AL, Y, caches)\n",
    "\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 iterations\n",
    "        if print_cost and i % 100 == 0 or i == epochs - 1:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % 100 == 0 or i == epochs:\n",
    "            costs.append(cost)\n",
    "    \n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57db1ccf-9a17-445e-96a4-d8394996a7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "Cost after iteration 0: 69173.69547086763\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-3b34bd7ff3c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# set layer number and sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0075\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-73fd928ffdb2>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X, Y, dims, learning_rate, epochs, print_cost)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_propagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward_propagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-5ab67ed9d1bc>\u001b[0m in \u001b[0;36mcompute_cost\u001b[1;34m(AL, Y)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#     AL = np.sum(AL, axis=1, keepdims=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_layer = x_train.shape[0] # set input layer size\n",
    "dims = [input_layer, 128, 128, 10] # set layer number and sizes\n",
    "\n",
    "parameters, costs = model(x_train[:, :10000], y_train[:, :10000], dims, learning_rate=0.0075, epochs = 1000, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84792498-4dd7-410e-9ba0-9cd11e180d69",
   "metadata": {},
   "source": [
    "<a name='9'></a>\n",
    "## Predict\n",
    "\n",
    "Use forward propagation to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbea25fd-a3a8-4c5d-83e1-a51e359dc4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    Predicts using learned parameters.\n",
    "    \n",
    "    Arguments:\n",
    "        X -- input data\n",
    "        parameters -- parameters of the prevously trained model\n",
    "        \n",
    "    Returns:\n",
    "        right_preds -- dictionary of the right predictions\n",
    "        wrong_preds -- dictionary of the wrong predictions\n",
    "        low_confidence_preds -- dictionary of the predictions with low confidence\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1] # number of examples\n",
    "    sum_rights = 0 # number of correct predictions\n",
    "    \n",
    "    predictions = {\n",
    "        \"right\": {},\n",
    "        \"wrong\": {},\n",
    "        \"low_confidence\": {}\n",
    "    }\n",
    "\n",
    "    # Forward propagation\n",
    "    preds, caches = forward_propagate(X, parameters)\n",
    "\n",
    "    for i in range(preds.shape[1]):\n",
    "        max_pred = preds[:, i]\n",
    "        prediction = np.argmax(max_pred, axis=None)\n",
    "        actual = y[:, i].squeeze()\n",
    "        \n",
    "        if max(max_pred) < 0.1: \n",
    "            predictions['low_confidence'][i] = {\n",
    "                'pred': prediction,\n",
    "                'actual': int(actual),\n",
    "                'confidence': preds[prediction, i]\n",
    "            }\n",
    "        elif prediction == actual:\n",
    "            sum_rights += 1\n",
    "            predictions['right'][i] = {\n",
    "                'pred': prediction,\n",
    "                'actual': int(actual),\n",
    "                'confidence': preds[prediction, i]\n",
    "            }\n",
    "        else:\n",
    "            predictions['wrong'][i] = {\n",
    "                'pred': prediction,\n",
    "                'actual': int(actual),\n",
    "                'confidence': preds[prediction, i]\n",
    "            }\n",
    "\n",
    "    accuracy = sum_rights/m\n",
    "    \n",
    "    return accuracy, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb6d03fe-257e-4833-8baf-734df978a6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:        0.85\n",
      "correct:         85\n",
      "mistakes:        14\n",
      "low confidence:  1\n"
     ]
    }
   ],
   "source": [
    "accuracy, predictions = predict(x_test[:, :100], y_test[:, :100], parameters)\n",
    "print('accuracy:       ', accuracy)\n",
    "print('correct:        ', len(predictions['right']))\n",
    "print('mistakes:       ', len(predictions['wrong']))\n",
    "print('low confidence: ', len(predictions['low_confidence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a9f30-6293-4a87-9ff6-86291cce5003",
   "metadata": {},
   "source": [
    "Print predictions dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaecf184-8d0e-465c-8bcc-c574ad8273f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 {'pred': 0, 'actual': 0, 'confidence': 0.09099509715751067}\n",
      "9 {'pred': 9, 'actual': 9, 'confidence': 0.06375696722317059}\n",
      "20 {'pred': 7, 'actual': 9, 'confidence': 0.0804298686074823}\n",
      "25 {'pred': 0, 'actual': 0, 'confidence': 0.07592232422169014}\n",
      "48 {'pred': 3, 'actual': 4, 'confidence': 0.05082428270524046}\n",
      "61 {'pred': 2, 'actual': 8, 'confidence': 0.09629625004345178}\n",
      "64 {'pred': 7, 'actual': 7, 'confidence': 0.08991692664991957}\n",
      "68 {'pred': 3, 'actual': 3, 'confidence': 0.06229189474186574}\n",
      "73 {'pred': 7, 'actual': 9, 'confidence': 0.07524066207908242}\n",
      "79 {'pred': 7, 'actual': 7, 'confidence': 0.053476509150439895}\n",
      "85 {'pred': 4, 'actual': 4, 'confidence': 0.07784257788976745}\n",
      "86 {'pred': 7, 'actual': 7, 'confidence': 0.09963417190104747}\n"
     ]
    }
   ],
   "source": [
    "print_num = 10\n",
    "num = 0\n",
    "\n",
    "for i in predictions['low_confidence']:\n",
    "    print(i, predictions['low_confidence'][i])\n",
    "    if num > print_num:\n",
    "        break\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50588ac4-804d-4260-b8d0-49a525fed23c",
   "metadata": {},
   "source": [
    "<a name='10'></a>\n",
    "### Print Images\n",
    "print images in predictions dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8419794d-eb69-45ba-b276-858b387f9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_images(X, p, num_images=20):\n",
    "    \"\"\"\n",
    "    Plots images where predictions and truth were different.\n",
    "        X -- dataset\n",
    "        y -- true labels\n",
    "        p -- predictions\n",
    "    \"\"\"\n",
    "    plt.rcParams['figure.figsize'] = (40.0, 40.0) # set default size of plots\n",
    "    plt_num = 1\n",
    "    row = 1\n",
    "    for index in p:\n",
    "        plt.subplot(1, num_images, plt_num)\n",
    "        plt.imshow(X[:, index].reshape(28,28), interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Prediction: \" + str(p[index]['pred']) + \" \\n Actual: \" + str(p[index]['actual']))\n",
    "        \n",
    "        plt_num += 1\n",
    "        if plt_num % 10 == 0: \n",
    "            row+= 1\n",
    "        if plt_num >= num_images:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88ca22-73c8-46cf-8495-6173e8157c24",
   "metadata": {},
   "source": [
    "Print wrong prediction images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1337e0e-2b5c-4de4-9f23-2c9f41d9b9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x2880 with 19 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_images(x_test, predictions['wrong'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15475c9f-d396-4bd1-9551-8269a60f6796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
